import streamlit as st
import pandas as pd

# è®€å–Excelæª”æ¡ˆ
def load_data(file_path):
    try:
        df = pd.read_excel(file_path)
        # ç¢ºä¿æ¬„ä½å­˜åœ¨
        required_columns = ['Date', 'Author', 'Title', 'Subtitle', 'URL', 'Category (20-class)']
        if not all(col in df.columns for col in required_columns):
            st.error("Excelæª”æ¡ˆç¼ºå°‘å¿…è¦æ¬„ä½ï¼šDate, Author, Title, Subtitle, URL, Category (20-class)")
            return None
        # è½‰æ›Dateç‚ºdatetimeæ ¼å¼ï¼Œä»¥ä¾¿æ’åº
        df['Date'] = pd.to_datetime(df['Date'], errors='coerce')
        return df
    except Exception as e:
        st.error(f"è®€å–æª”æ¡ˆå¤±æ•—ï¼š{e}")
        return None

# é¡¯ç¤ºåˆ†é æ–‡ç« çš„å‡½æ•¸
def display_paginated_articles(df):
    if df.empty:
        st.info("ç„¡æ–‡ç« ã€‚")
        return

    # åˆå§‹åŒ– session state ä¸­çš„é ç¢¼
    if 'page' not in st.session_state:
        st.session_state.page = 0

    # è¨ˆç®—ç¸½é æ•¸
    items_per_page = 5
    total_pages = (len(df) + items_per_page - 1) // items_per_page

    # é¡¯ç¤ºç•¶å‰é çš„æ–‡ç« 
    start = st.session_state.page * items_per_page
    end = start + items_per_page
    page_df = df.iloc[start:end]

    # ä½¿ç”¨ CSS ä¾†æ¸›å°‘ç•™ç™½
    st.markdown("""
    <style>
    .stMarkdown div {
        margin-top: -10px;
        margin-bottom: -10px;
    }
    </style>
    """, unsafe_allow_html=True)

    for index, row in page_df.iterrows():
        # ä½¿ç”¨ columns ä¾†å°é½Šæ¨™é¡Œå’Œé€£çµ
        col1, col2 = st.columns([4, 1])  # èª¿æ•´æ¯”ä¾‹ä½¿é€£çµå°é½Šå³é‚Š
        with col1:
            st.markdown(f"â™¦ **{row['Title']}**", unsafe_allow_html=True)
        with col2:
            st.markdown(f"[ğŸ”—é–±è¦½é€£çµ](https://freedium.cfd/{row['URL']})", unsafe_allow_html=True)
        
        # åˆä½µ subtitle, author å’Œ date åˆ°ä¸€è¡Œä»¥ç¸®çŸ­ç‰ˆé¢
        subtitle = row['Subtitle'] if pd.notna(row['Subtitle']) else ''
        date_str = row['Date'].strftime('%Y-%m-%d') if pd.notna(row['Date']) else 'N/A'
        st.markdown(f"{subtitle} â€” {row['Author']}, {date_str}", unsafe_allow_html=True)
        st.markdown("---")
    
    # åˆ†é æ§åˆ¶æŒ‰éˆ•
    col1, col2, col3 = st.columns([1, 1, 1])
    with col1:
        if st.button("ä¸Šä¸€é ") and st.session_state.page > 0:
            st.session_state.page -= 1
            st.rerun()
    with col3:
        if st.button("ä¸‹ä¸€é ") and st.session_state.page < total_pages - 1:
            st.session_state.page += 1
            st.rerun()
    st.write(f"é ç¢¼: {st.session_state.page + 1} / {total_pages}")

# ä¸»ç¨‹å¼
st.title("Medium Digest-Web")

# ä¸Šå‚³æˆ–æŒ‡å®šExcelæª”æ¡ˆï¼ˆé€™è£¡å‡è¨­æª”æ¡ˆåœ¨åŒç›®éŒ„ï¼Œæ‚¨å¯ä»¥æ”¹æˆä¸Šå‚³åŠŸèƒ½ï¼‰
file_path = 'Medium digest (classified).xlsx'  # æ›¿æ›æˆæ‚¨çš„Excelæª”æ¡ˆè·¯å¾‘
df = load_data(file_path)

if df is not None:
    # å®šç¾© AI å’Œ é AI é¡åˆ¥
    ai_categories = [
        "Retrieval-Augmented Generation (RAG)",
        "Agentic AI & AI Agents",
        "Large Language Models (LLM)",
        "Multimodal AI (Vision/Audio/Video + Language)",
        "Computer Vision (CV)",
        "Speech & Audio AI",
        "Natural Language Processing (non-LLM)",
        "Fine-tuning & Embeddings",
        "Prompt Engineering & In-Context Learning",
        "AI Evaluation & Metrics",
        "Deep Learning (non-LLM)",
        "Machine Learning (Classical)",
        "AI Infrastructure, MLOps & Frameworks",
        "AI Applications (Business/Dev/Productivity)",
        "AI Policy, Governance & Safety"
    ]

    non_ai_display_categories = [
        "Software Engineering & Programming",
        "Data Science & Statistics",
        "Technology/Science",
        "Finance/Economics/Business",
        "Society/Culture/Other"
    ]

    # åœ¨å´é‚Šæ¬„é¡¯ç¤ºæ‘ºç–Šåˆ—è¡¨
    st.sidebar.header("æ–‡ç« åˆ†é¡")
    selected_labels = []

    with st.sidebar.expander("AIï¼ˆ15 é¡ï¼‰"):
        select_all_ai = st.checkbox("å…¨é¸ AI")
        if select_all_ai:
            selected_labels.extend([label for label in ai_categories if label in df['Category (20-class)'].unique()])
        else:
            for label in ai_categories:
                if label in df['Category (20-class)'].unique():
                    label_count = len(df[df['Category (20-class)'] == label])
                    if st.checkbox(f"{label} ({label_count} ç¯‡æ–‡ç« )", value=False):
                        selected_labels.append(label)

    with st.sidebar.expander("é AIï¼ˆ5 é¡ï¼‰"):
        select_all_non_ai = st.checkbox("å…¨é¸ éAI")
        if select_all_non_ai:
            selected_labels.extend([f"Non-AI {label}" for label in non_ai_display_categories if f"Non-AI {label}" in df['Category (20-class)'].unique()])
        else:
            for display_label in non_ai_display_categories:
                label = f"Non-AI {display_label}"
                if label in df['Category (20-class)'].unique():
                    label_count = len(df[df['Category (20-class)'] == label])
                    if st.checkbox(f"{display_label} ({label_count} ç¯‡æ–‡ç« )", value=False):
                        selected_labels.append(label)

    # é¡¯ç¤ºæœå°‹æ¡†åœ¨æ¨™é¡Œä¸‹æ–¹
    search_term = st.text_input("åœ¨Titleæˆ–Subtitleä¸­æœå°‹")

    # é‡ç½®é ç¢¼ç•¶æœå°‹æˆ–é¸æ“‡æ”¹è®Šæ™‚ï¼ˆå¯é¸ï¼Œä½†æœ‰åŠ©æ–¼ä½¿ç”¨è€…é«”é©—ï¼‰
    if 'last_search' not in st.session_state or st.session_state.last_search != search_term:
        st.session_state.page = 0
        st.session_state.last_search = search_term
    if 'last_selected' not in st.session_state or st.session_state.last_selected != selected_labels:
        st.session_state.page = 0
        st.session_state.last_selected = selected_labels[:]

    # å…ˆæ ¹æ“šé¸æ“‡çš„labeléæ¿¾è³‡æ–™
    if selected_labels:
        filtered_df = df[df['Category (20-class)'].isin(selected_labels)]
    else:
        filtered_df = df
    filtered_df = filtered_df.sort_values('Date', ascending=False)

    if search_term:
        # è™•ç†æœå°‹ï¼šå¿½ç•¥å¤§å°å¯«ï¼Œè™•ç†NaNï¼Œåœ¨éæ¿¾å¾Œçš„dfä¸Šæœå°‹
        mask_title = filtered_df['Title'].astype(str).str.contains(search_term, case=False, na=False)
        mask_subtitle = filtered_df['Subtitle'].astype(str).str.contains(search_term, case=False, na=False)
        search_df = filtered_df[mask_title | mask_subtitle]
        st.subheader(f"æœå°‹çµæœ (å…± {len(search_df)} ç­†)")
        if not search_df.empty:
            display_paginated_articles(search_df)
        else:
            st.info("ç„¡ç¬¦åˆæœå°‹çµæœã€‚")
    else:
        display_paginated_articles(filtered_df)